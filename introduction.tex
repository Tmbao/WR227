% \addbibresource{refs.bib}

\section{Introduction} \label{section:introduction}
Alongside the intensive growth of social networks such as Facebook or Twitter, the information that users want to share is not only text but also other complex types, especially images. In January 2009, Kaplan et al. state that there are over 3 billion photos on Flickr \cite{Kaplan201059}. And in 2012, it is recorded that 250 million photos are uploaded to Facebook everyday \cite{1}. This fact creates a huge demand of managing and querying data from huge amount of information in different formats (text, image, video, sound \ldots).

Therefore, the tendency to search not only by text but also some special features of other complex types such as images is currently one of the most popular concerns. Many text retrieval techniques are applied to image retrieval since search by text and by images share many common characteristics. Nonetheless, there are still numerous differences between text and image retrieval in many criterion such as amount of words contained in each query, how words are segmented and ordered... For example, A user who types a three-word text query may in general be searching for documents containing those three words in any order, at any positions in the document. A visual query however, since it is selected
from a sample image, automatically and inescapably includes visual words in a spatial configuration corresponding to some view of the object. Thus, despite of the existence of many effective image retrieval system such as Google and Bing, the problem of improving performance of visual search systems remains an interest of many research labs and corporations.

To query visual data using a single image, one of many approaches is template matching method, i.e. a technique for finding small parts of an image which match a template image \cite{brunelli_template_matching}, \cite{Rosenfeld4309663, Gharavi913587}. Another popular technique is to evaluate the similarity of two images by comparing some regions which seem to be the interested points of the images, namely features matching \cite{Belongie710790, Rubner, Viola990517}. The algorithm that the authors choose to discuss in this paper is Bag-of-Words (BoW) \cite{3} which is used by many different image retrieval systems \cite{3, 2, 7}. A reason why Bag-of-Words is widely used is that it allows parts of a query image to appear flexible in the result images. Hence, BoW model is a really potential approach and is focused by many research groups.

However, due to the flexibility among parts of the query images, BoW might not fully exploit the spatial relations among the components of images. This fact motivates our investigation to prove that cooperating the spatial information can increase the precision of BoW model. Our key idea in the experiments is using Random sample consensus (RANSAC) to eliminate the effects of trash features, i.e. features that conflict with spatial structures among components of the object. Our experiments performed on Oxford Building 5K Dataset shows that using an extra spatial rerank step has a huge impact on the BoW model in term of mean Average Precision (an increase from 0.676 to 0.741). This work's main contribution is the proof that spatial information is really useful when retrieving visual information and promote the research of enforcing spatial consistency to image retrieval systems.

The rest of this paper is organized as follows. In section \ref{section:background_relatedworks}, we review the background and related words in image retrieval and image classification. The core steps of the BoW model and how we conduct experiments are presented in section \ref{section:method}. Section IV shows experiment results and evaluations. The conclusion and future works are discussed in section V.
